{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b8bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import BBHX_PhenomD\n",
    "import time\n",
    "import numpy as np\n",
    "from pycbc.waveform import get_td_waveform, get_fd_waveform\n",
    "from pycbc.catalog import Merger\n",
    "from pycbc.filter import resample_to_delta_t, highpass, matched_filter, sigma\n",
    "import pycbc.psd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.cosmology import Planck13 as cosmo\n",
    "import pycbc.waveform.spa_tmplt as pyspt\n",
    "from pycbc import waveform\n",
    "from pycbc.inference.io import loadfile\n",
    "import pandas\n",
    "import h5py\n",
    "import pickle\n",
    "from bbhx.utils.constants import *\n",
    "from bbhx.utils.transform import *\n",
    "from pycbc.conversions import  mchirp_from_mass1_mass2\n",
    "import astropy.coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b3bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the results files from the inference, you may need to cd into where the hrd files were saved ##\n",
    "\n",
    "##%cd FOLDER PATH, for example /mnt/d/INFERENCE_FOLDER/\n",
    "\n",
    "\n",
    "def lf(file):           \n",
    "    return loadfile(\"{}\".format(file),\"r\")\n",
    "results_A ={}\n",
    "for i in range(10):\n",
    "    results_A[i] = lf(\"lisa_smbhb_GAL_A_{}.hdf\".format(i))\n",
    "results_A\n",
    "\n",
    "results_B ={}\n",
    "for i in range(10):\n",
    "    results_B[i] = lf(\"lisa_smbhb_GAL_B_{}.hdf\".format(i))\n",
    "    \n",
    "    \n",
    "    \n",
    "def bayes_results(filename):\n",
    "    bayes_factor = np.array([results_A[i].log_evidence[0] - results_B[i].log_evidence[0] for i in range(10)])\n",
    "    bayes_factor_error = [np.sqrt(results_A[i].log_evidence[1]**2 + results_B[i].log_evidence[1]**2) for i in range(10)]\n",
    "    np.savez(f\"{filename}.npz\",bf = bayes_factor, ang = ang_sep, err=bayes_factor_error )\n",
    "    return bayes_factor,bayes_factor_error\n",
    "  ## This function returns our LOG(BF) and its error (added in quadrature), and saves it if we want to compare results ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac42ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('false_dict.pkl', 'rb') as f:\n",
    "    GAL_B = pickle.load(f)    \n",
    "GAL_B\n",
    "\n",
    "with open('merge_dict_A.pkl', 'rb') as f:\n",
    "    GAL_A = pickle.load(f)\n",
    "## Unpickle the dictionaries we made in \"waveform.py\" ##\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "dict_of_df_B = {}\n",
    "df_keys = ['distance',\n",
    " 'inclination',\n",
    " 'loglikelihood',\n",
    " 'logwt',\n",
    " 'mchirp',\n",
    " 'spin1z',\n",
    " 'spin2z']\n",
    "\n",
    "### Here we translate our dictionaries into pandas dataframes for ease of use ###\n",
    "### GAL_B contains the TRUE parameters, dict_of_df contains the inference results ###\n",
    "\n",
    "for i,merger in enumerate(results_B):\n",
    "    dict_of_df_B[merger] = pandas.DataFrame(np.array([results_B[merger][\"samples\"][i] for i in list(results_B[i]['samples'].keys())])).T\n",
    "    dict_of_df_B[merger].columns =['distance',\n",
    " 'inclination',\n",
    " 'loglikelihood',\n",
    " 'logwt',\n",
    " 'mchirp',\n",
    " 'spin1z',\n",
    " 'spin2z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b87b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_dist = cosmo.luminosity_distance(0.5).value\n",
    "ang_sep = [astropy.coordinates.angular_separation(true_long,true_lat,gal_b_long[i],gal_b_lat[i]) for i in range(10)]\n",
    "\n",
    "true_lat = GAL_B[0][\"beta\"]\n",
    "true_long  = GAL_B[0][\"lam\"]\n",
    "true_inc = 1.GAL_B[0][\"inc\"]\n",
    "\n",
    "gal_b_long = np.array([GAL_B[i][\"lam\"] for i in range(10)]) #### These are our TRUE PARAMETERS ###\n",
    "gal_b_lat  = np.array([GAL_B[i][\"beta\"] for i in range(10)])\n",
    "gal_b_spin1_true = np.array([GAL_B[i][\"chi1z\"] for i in range(10)])\n",
    "gal_b_spin2_true = np.array([GAL_B[i][\"chi2z\"] for i in range(10)])\n",
    "gal_b_dist_true = np.array([GAL_B[i][\"dist\"] / (PC_SI * 1e6) for i in range(10)])\n",
    "gal_b_true_mass = np.array([mchirp_from_mass1_mass2(GAL_B[i][\"m1\"],GAL_B[i][\"m2\"]) for i in range(10)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gal_b_spin1z =  np.array([dict_of_df_B[i][\"spin1z\"].iloc[-1] for i in range(10)])  \n",
    "gal_b_spin2z =  np.array([dict_of_df_B[i][\"spin2z\"].iloc[-1] for i in range(10)])  \n",
    "gal_b_inc =  np.array([dict_of_df_B[i][\"inclination\"].iloc[-1] for i in range(10)])  \n",
    "gal_b_mass =  np.array([dict_of_df_B[i][\"mchirp\"].iloc[-1] for i in range(10)])\n",
    "gal_b_dist =  np.array([dict_of_df_B[i][\"distance\"].iloc[-1] for i in range(10)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_results(filename):\n",
    "    bayes_factor = np.array([results_A[i].log_evidence[0] - results_B[i].log_evidence[0] for i in range(10)])\n",
    "    bayes_factor_error = [np.sqrt(results_A[i].log_evidence[1]**2 + results_B[i].log_evidence[1]**2) for i in range(10)]\n",
    "    np.savez(f\"{filename}.npz\",bf = bayes_factor, ang = ang_sep, err=bayes_factor_error )\n",
    "    return bayes_factor,bayes_factor_error\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5049499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_res(filename):\n",
    "    np.savez(f\"{filename}.npz\",bf = bayes_factor, ang = ang_sep, err=bayes_factor_error )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1363fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_statement(plot=False):\n",
    "    bayes_factor.sort()\n",
    "    ang_sep.sort()\n",
    "    plt.figure(dpi = 200,figsize = (10,8))\n",
    "    points_within_centre_circle = []\n",
    "    point_within_torus = []\n",
    "    for idx,i in enumerate(ang_sep):\n",
    "        point_counter = 0\n",
    "        point_counter_circle = 0\n",
    "        angle = np.linspace( 0 , 2*np.pi , 100 ) \n",
    "\n",
    "        radius = i\n",
    "        small_r = ang_sep[idx]\n",
    "        large_r = ang_sep[idx-1]\n",
    "        for j in range(len(data_x)):\n",
    "            if (data_x[j] - np.pi/2)**2 + (data_y[j] - 0 )**2 > large_r **2 and (data_x[j] - np.pi/2)**2 + (data_y[j] -  0)**2 < small_r **2:\n",
    "                point_counter+=1\n",
    "        point_within_torus.append(point_counter)\n",
    "        #print(point_counter)\n",
    "\n",
    "        \n",
    "        x = radius * np.cos( angle ) +np.pi/2\n",
    "        y = radius * np.sin( angle ) \n",
    "        if bayes_factor[idx]>=0 and plot ==True:\n",
    "            plt.plot(x,y,'g',alpha=1,label =  f\"{bayes_factor[idx]:.2f}\")\n",
    "        elif bayes_factor[idx]<=0 and plot == True:\n",
    "            plt.plot(x,y,'r--',alpha=1,label =  f\"{bayes_factor[idx]:.2f}\")\n",
    "        for j in range(len(data_x)):\n",
    "            if (data_x[j] - np.pi/2)**2 + (data_y[j] -  0 )**2 < radius**2 and idx == 0 :\n",
    "                point_counter_circle += 1\n",
    "        points_within_centre_circle.append(point_counter_circle)\n",
    "        #print(point_counter_circle)\n",
    "        #plt.plot(x,y)\n",
    "\n",
    "    legend=plt.legend(title=\"Ln(BF) for each ring\",fontsize = 15)\n",
    "    plt.setp(legend.get_title(),fontsize='x-large')\n",
    "    #plt.xlim(np.pi/2)\n",
    "    #plt.ylim(np.pi/2)\n",
    "\n",
    "\n",
    "    point_within_torus[0] = points_within_centre_circle[0]\n",
    "    point_within_torus = np.array(point_within_torus)\n",
    "    points_unresolvable = sum(point_within_torus[bayes_factor<=1])\n",
    "    print(\"Fraction unresolvable:\",points_unresolvable/500 * 100\n",
    "\n",
    "\n",
    "\n",
    "    if plot == True:\n",
    "        plt.scatter(data_x,data_y,s=10.5)\n",
    "        plt.scatter(np.pi/2,0,s=80,marker='+')\n",
    "        plt.xlabel(\"Elliptic longitude (radians)\",fontsize = 24)\n",
    "        plt.ylabel(\"Elliptic latitude(radians)\",fontsize = 24)\n",
    "        plt.xticks(fontsize = 18)\n",
    "        plt.yticks(fontsize = 18)\n",
    "          \n",
    " inv_bayes_factor = np.array([results_B[i].log_evidence[0] - results_A[i].log_evidence[0] for i in range(10)])\n",
    "    p_b = np.exp(sorted(inv_bayes_factor,reverse=True)) / point_within_torus\n",
    "    \n",
    "          \n",
    "          \n",
    "    if plot == True:\n",
    "        plt.figure(dpi= 250,figsize = (12,10))\n",
    "        plt.plot(ang_sep,p_b)\n",
    "        plt.xticks(np.linspace(min(ang_sep),max(ang_sep),5),fontsize =18)\n",
    "        plt.yticks(fontsize = 18)\n",
    "        plt.xlabel(\"Angular separation (radians)\",fontsize = 20)\n",
    "        plt.ylabel(\"Relative probability of galaxy B containing the event\",fontsize = 20)\n",
    "        plt.grid()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
